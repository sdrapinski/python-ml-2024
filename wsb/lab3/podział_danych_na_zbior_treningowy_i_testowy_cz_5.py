# -*- coding: utf-8 -*-
"""Podział danych na zbior treningowy i testowy cz.5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aoZ8gQN8f1FlWNg5v0iR5V-0S5vVBbAA

###**Podział danych na zbiór treningowy i testowy**

###**1. Standardowy podział danych na zbiór treningowy i testowy**

###**Import bibliotek**
"""

import pandas as pd
from sklearn.model_selection import train_test_split

"""###**Wygenerowanie przykładowych danych**"""

df = pd.DataFrame({"x": list(range(100)),"y":["a", "b", "c", "d"]*25})

df.head()

"""###**Zastosowanie funkcji train_test_split()**

Jako wyjście dostajemy krotkę dwóch elementów - również będą to ramki danych.

*test_split* - frakcja wierszy, które chcielibyśmy widzieć w zbiorze testowym.
"""

(train, test) = train_test_split(df, test_size=0.2)

"""Warto zwrócić uwagę, iż wartości dla zbioru testowego zostały wymieszane - ułożone w losowej kolejności."""

test.head()

test.shape

train.shape

"""Możemy również danych w zbiorze testowym nie mieszać.

Dzieje się tak gdy paramtr shuffle ustawimy na false.

Pierwszych 80% danych jest branych do zbioru treningowego, a pozostałe 20% do zbioru testowego.
"""

(train, test) = train_test_split(df, test_size=0.2, shuffle=False)

"""Zbiór nie jest wymieszany - jest ułożony w kolejności."""

test.head()

"""###**2. Cross walidacja**"""

import numpy as np

x1 = np.random.normal(1, 1, 100)
y1 = np.random.normal(1, 1, 100)

x2 = np.random.normal(-1, 1, 100)
y2 = np.random.normal(-1, 1, 100)

l1 = np.zeros(100)
l2 = np.ones(100)


x = np.concatenate((x1, x2))
y = np.concatenate((y1, y2))
l = np.concatenate((l1, l2))

df = pd.DataFrame({"x": x.reshape(-1), "y": y.reshape(-1), "label": l})
df.head()

df.tail()

"""###**Zastosujemy naiwny klasyfikator bayesowki.**

Jako, że mamy do czynienia z próbkami z rozkładów normlanych zastosouejmy wersję GaussianNB.
"""

from sklearn.naive_bayes import GaussianNB

"""###**Tworzę model** - obiekt klasy GaussianNB"""

model = GaussianNB()

from sklearn.model_selection import KFold #Klasa obiektów KFold - obikety służące do manipulowania danymi w procesie cross walidacji.

from sklearn.model_selection import cross_validate, cross_val_score #Funkjca, która nieco uprości proces

"""###Obiekt klasy KFold

Liczba podziałów na zbiór treningowy i testowy.
W zalezności od liczby podziałów n_split różna będzie również proporcja danych uczących i testowych.
Przykładowo jeżeli liczba tych podziałów wyniesie 5 wówczas w zbiorze testowym znajdzie się za każdym razem 20% wierszy z tego zbioru, natomiast w zbiorze uczacym znajdzie się 80%.

Parametr *shuffle()* wskazuje czy dane będą losowane i będziemy po prostu brali kolejne wiersze ze zbioru w kolejności w jakiej zbiór powstawał.
"""

kf = KFold(n_splits=5, shuffle=True)

"""###Generator umożliwiający podziały

Jak możemy zauważyć w efekcie otrzymamy numery indeksów elementów, które mają znaleźć się w zbiorze uczacym i zbiorze testowym w kolejnych eksperymentach.
"""

list(kf.split(df))

"""*Jak można to teraz zastosować?*

Można to zastsować w ten sposób, że każdy z tych elementów (każdą z tych wersji) zastosoujemy do jakiegoś eksperymentu, do wyuczenia naszego modelu i później jego przetestowania.

Musimy to zrobić ręcznie.

Przykładowo możemy to zrobić w pętli:

W rezultacie otrzymaliśmy 5 zestawów dokładności na zbiorze treningowym i testowym.
"""

for train_index, test_index in kf.split(df):
  train = df.iloc[train_index]
  test = df.iloc[test_index]
  model.fit(train.iloc[:,:-1], train.iloc[:,-1])
  print(f"Train score: {model.score(train.iloc[:, :-1], train.iloc[:, -1])}")
  print(f"Test score: {model.score(test.iloc[:, :-1], test.iloc[:, -1])}")
  print()

"""###**Inny sposób rozwiązania - prościej**

Zapis jednolinijkowy
"""

cross_validate(model, df.iloc[:,:-1], df.iloc[:,-1], cv=5, return_train_score=True)

cross_val_score(model, df.iloc[:,:-1], df.iloc[:,-1], cv=5)

