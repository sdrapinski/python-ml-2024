# -*- coding: utf-8 -*-
"""Uczenie nadzorowane cz.3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q58EWOl7kY90hJl8X9NdYqiDem0m-dIN

###**1. Regresja liniowa**

###**Generujemy dane**
"""

import numpy as np

"""###Generuje zmienną niezależną

Zmienna zawierająca próbkę z rozkładu jednostajnego.

Funkcja *uniform()* z modułu random pozwala generować próbki z **rozkładu jednostajnego** na zadanym odcinku.
"""

x = np.random.uniform(-5, 5, 100)

"""###Generuje zmienną zależną"""

y = 5 * x + 3 + np.random.normal(0, 3, 100)

"""Zmienna typu **array**.

###Zwróćmy uwagę, iż nasza macierz jest jednowymiarowa.

W dalszej części naszej pracy będziemy musieli zmodyfkować tę macierz.
"""

x

"""###Zwróćmy uwagę, iż nasza macierz jest jednowymiarowa."""

y

import matplotlib.pyplot as plt

plt.figure(figsize=(7, 7))
plt.scatter(x, y, color="red")

"""###*Pojawia się pytanie jak zidentyfikować parametry linii w danych?*

Możemy użyć klasy, która oprogramowuje niejako algorytm poszukiwania prostej regresji w problemie regresji liniowej.

Klasa ta jest zawarta w bibliotece sklearn.
"""

from sklearn.linear_model import LinearRegression

"""###**Tworze obiekt klasy LinearRegresion**"""

model = LinearRegression()

"""**Biblioteka sklearn** posiada pewną konwencję jeśli chodzi o uczenie modeli oprogramowanych jako klasy.

W klasie tej jest metoda *fit()* - metoda do nauczenia modelu odpowiednich parametrów przy pomocy zbioru uczącego.

###Metoda zmieniająca rozmiar (kształt) macierzy

Wektor o stu elemnetach.
"""

x.shape

"""###Zmnieniamy kształt tego elemntu.

W rezultacie otrzymujemy wektor pionowy - macierz dwuwymiarowa.

W *Numpy* metoda shape() wymaga podania wszystkich rozmiarów.

Zatem jeśli chcemy przekształcić już jakąś istniejącą macierz - musimy wiedzieć ile zawiera ona elementów.
"""

x.reshape((100, 1))

"""Istnieje jednak sposób aby ominąć konieczność dokładnego okreslenie liczby elemnetów w metodzie *reshape()*.

możemy to zrobić w następujący sposób:


-1 podane jako pierwszy element macierzy to ten wymiar, który *Numpy* powinien sobie dostosować.
"""

x.reshape(-1, 1)

"""###Uczę model"""

model.fit(x.reshape(-1, 1), y)

"""###Sprawdzamy jak dobrze model został dopasowany

W normalnych warunkach dopasowanie sprawdzamy na zbiorze testowym, nie na zbiorze uczącym.

Na tym etapie nauki nie zdefiniowaliśmy zbioru testowego.

Sprawdzamy zatem **dopasowanie modelu do danych uczacych**.

Chodzi jedynie o to aby przejść kolejne kroki procesu uczenia modelu.

Obiekty, które reprezentują modele posiadają metodę score() - metoda ta wylicza najważniejsze współczynniki określające jakoś modelu.

W przypadku regresji liniowej tym współczynnikiem będzie **R^2**.

Współczynnik ten określa jak bardzo zmienność danych w zbiorze ocenianym jest wyjaśniana przez model, który jest dopasowany.  

Innymi słowy ile z tej zmienności (rozrzutu) punktów w chmurce można wyjaśnić tym, że układają się one wzdłuż prostej.
"""

model.score(x.reshape(-1, 1), y)

"""###Jeżeli chcemy sprawdzić jak dobrze udało się nam wyestymować parametry prostej - odczytujemy to z parametrów modelu.

Sprawdźmy jak baardzo dobrze udało nam się przybliżyć 3
"""

model.intercept_

"""Sprawdźmy jak dobrzer udało się nam wyestymować współczynnik kierunkowy czyli jak bardzo dobrze udało się na 5 przybliżyć."""

model.coef_

"""###**Rysujemy wykres**"""

x_new = np.array([-5, 5])

"""*Jak przeliczyć wartości oczekiwane z modelu dla nowych danych?*"""

model.predict(x_new.reshape(-1, 1))

plt.figure(figsize=(7,7))
plt.scatter(x, y, color="red")
plt.plot(x_new, model.predict(x_new.reshape(-1, 1)), color="blue")

"""###**2. Klasyfikacja**

Klasyfikacja punktów na płaszczyźnie.

Staraliśmy się znaleźć na podstawie danych o klasach czy etykietach punktów na płaszczyźnie pewien uniwersalny przepis jak przypisywać etykiety do punktów, które ewentualnie pojawią się w zbiorze.

Podział płaszczyzny na obszary, w których wszystkie nowe punkty miałyby być opatrywane etykietami odpowiadającymi etykiecie danego obszaru.

###**Generujemy dane**

Generujemy dane z generatora liczby pseudolosowych z biblioteki Numpy.

Punkty klasy pierwszej:

współrzędne x-owe z rozkładu normlanego.
"""

x1 = np.random.normal(1, 1, 100)
y1 = np.random.normal(1, 1, 100)

x2 = np.random.normal(-1, 1, 100)
y2 = np.random.normal(-1, 1, 100)

"""Sto punktów wygenerowanych z rozkładu normalnego"""

x1

"""Łącze wektory aby x1 i y1 oraz x2 i y2 mieć w jednej zmiennej.

###**Łącze dwa wektory**
"""

x = np.concatenate((x1, x2))
y = np.concatenate((y1, y2))

"""###**Generuje etkiety dla tych punktów**

Metoda *zeros()* generuje wektor zawierający same zera.

Metoda *ones()* generuje wektor zawierający same jedynki.
"""

l1 = np.zeros(100)

l2 = np.ones(100)

l = np.concatenate((l1, l2))

x

l

"""###**Wyrysujmy te punkty**

Paleta kolorów: https://xkcd.com/color/rgb/
"""

plt.figure(figsize=(7,7))
plt.scatter(x1, y1, color="xkcd:golden yellow")
plt.scatter(x2, y2, color="xkcd:indigo")

"""Chcemy zbudować model, który pozwoli nam okreslić jak przydzielić nowe punkty, ktore ewentualnie na wejściu do takiego modelu by się pojawiły.

Skorzystamy z **naiwnego klasyfikatora bayesowskiego**.

Jako, że mamy do czynienia z próbką z rozkładu normalnego, skorzystamy z klasyfikatora w oparciu o rozkład normalny.
"""

!pip install scikit-learn
from sklearn.naive_bayes import GaussianNB

"""###**Tworzę obiekt tej klasy**"""

model = GaussianNB()

"""###**Trenujemy model** - metoda *fit()*

W tym celu skorzystamy z generatora *zip()*, który zwróci pary wartości x i y.
"""

model.fit(list(zip(x, y)), l)

"""Współczynnikiem, który jest obliczany przez *metodę score* jest dokładność (**accuracy**).

**Accuracy** - stosunek procentowy obiektów, które zostały poprawnie sklasyfikowane względem obiektów, które zostały sklasyfikowane niepoprawnie.

Podobnie jak w poprzednim przykładzie (niepoprawnie ze sztuką) - obliczymy dopasowanie modelu do danych użyję danych uczących.

Powinniśmy użyć danych testowych, niezależnych od danych testowych.
"""

model.score(list(zip(x, y)), l)

"""###**Rysujemy wykres**

Wskażemy gdzie są te obszary przydzielone do kategorii żółtych i gdzie są te obszary przydzielone do kategorii niebieskich.

Wygenerujemy punkty na gęstej siatce pokywającej prostokąt objęty obszarem wykresu.

###**Generuje punkty siatki.**

Aby wygenerować punkty siatki korzystamy z metody *meshgrid()*.

Funkjca ta przyjmuje jako dane wejściowe pewną strukturę.

Może to być lista czy też macierz.
"""

# (new_x, new_y) = np.meshgrid([0, 1, 2, 3],  [0, 2, 4])

"""Na wyjściu otrzymujemy macierz, która można zastosować do wygenrowania par punktów, które sa punktami umieszczonymi na siatce.

Kombinacje paratrów z list: 00, 10, 20, 30, 02, 12, 22, 32 itd.


"""

(new_x, new_y) = np.meshgrid(np.array(range(-100,100)) / 20, np.array(np.arange(-100,100)) / 20)

new_x[1:5]

new_y [1:5]

"""Aby pozbyć się struktury macierzy.

Funkcja zip przeiteruje się przez new_x, new_y
"""

new_data = list(zip(new_x.reshape(-1), new_y.reshape(-1)))

"""###**Szacujemy etykiety**"""

new_l = model.predict(new_data)

import pandas as pd

df = pd.DataFrame({"x": new_x.reshape(-1), "y": new_y.reshape(-1), "l": new_l})

df.head()

"""###**Rysujemy wykres**"""

plt.figure(figsize=(7,7))
plt.scatter(df[df["l"] == 0]["x"], df[df["l"] == 0]["y"], color="xkcd:blue")
plt.scatter(df[df["l"] == 1]["x"], df[df["l"] == 1]["y"], color="xkcd:lemon yellow")
plt.scatter(x1, y1, color="xkcd:golden yellow")
plt.scatter(x2, y2, color="xkcd:indigo")

